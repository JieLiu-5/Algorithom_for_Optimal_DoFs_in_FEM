
\documentclass[review,3p]{elsarticle}

\usepackage{lineno}       
\modulolinenumbers[5]
\usepackage{subcaption}             % used in subtable



\usepackage{graphicx}


\usepackage{amsmath, amsfonts, amsthm}            % for subequations

\usepackage{mathtools, amssymb}          % for \leqslant
\newcommand{\ddn}[2]{\frac{\mathrm{d}}{\mathrm{d}#1}#2}
\newcommand{\ddt}{\frac{\mathrm{d}}{\mathrm{d}t}}


\usepackage{upgreek}
% \usepackage{tipa}
\usepackage[dvipsnames]{xcolor}
\usepackage{soul}
\usepackage{multirow}

\usepackage{array}
\newcolumntype{C}[1]{>{\centering\let\newline\\\arraybackslash\hspace{0pt}}m{#1}} 
\newcolumntype{L}[1]{>{\raggedright\let\newline\\\arraybackslash\hspace{0pt}}m{#1}} 
\newcolumntype{R}[1]{>{\raggedleft\let\newline\\\arraybackslash\hspace{0pt}}m{#1}} 

\usepackage{booktabs}       % http://ctan.org/pkg/booktabs

\newcommand{\tabitem}{~~\llap{\textbullet}~~}           % for items inside a table
\usepackage{makecell}       % used inside a table
\usepackage{pbox}           % for weak form 3
\usepackage{empheq}
\newcommand*\widefbox[1]{\fbox{\hspace{2em}#1\hspace{2em}}}


\usepackage{colortbl}
\usepackage{esvect}
\usepackage{spreadtab}
\usepackage{numprint}
\usepackage{xstring}
\renewcommand*{\thefootnote}{\fnsymbol{footnote}}
\usepackage[symbol]{footmisc}

\usepackage{siunitx}

\makeatletter       % for rom in deal.ii symbol
\newcommand*{\rom}[1]{\expandafter\@slowromancap\romannumeral #1@}
\makeatother

\usepackage{enumitem}

\usepackage{hyperref}               


\usepackage{cleveref}
\crefformat{section}{\S#2#1#3} % see manual of cleveref, section 8.2.1
\crefformat{subsection}{\S#2#1#3}
\crefformat{subsubsection}{\S#2#1#3}

\captionsetup[figure]{labelfont={bf},name={Fig.},labelsep=period}
\captionsetup[table]{labelfont={bf},name={Table},labelsep=space,justification=justified,singlelinecheck=false}      % the last two commands for left-align the caption

\usepackage[labelformat=simple]{subcaption}	        	% order of subfigure with brackets
\renewcommand\thesubfigure{(\alph{subfigure})}
\renewcommand\thesubtable{(\alph{subtable})}


\usepackage{wrapfig}
\usepackage{lipsum}

\usepackage{pgfplots}       % for tikzpicture
\pgfplotsset{compat=1.7}

\pdfsuppresswarningpagegroup=1      % eliminate warning 'multiple pdfs with page group included in a single page'

\usepackage[ruled,linesnumbered]{algorithm2e}		% for algorithm

\begin{document}

% \pagenumbering{Alph}

\begin{frontmatter}

\title{Balancing truncation and round-off errors in practical FEM: one-dimensional analysis}

 \author[1]{Yongliang Liu\corref{cor1}}
 \ead{j.liu-5@tudelft.nl}
 \author[1]{Matthias M\"oller}
 \ead{m.moller@tudelft.nl}
 \author[1]{Henk M. Schuttelaars}
 \ead{h.m.schuttelaars@tudelft.nl}
 
 \address[1]{Delft Institute of Applied Mathematics\\ Delft University of Technology\\ Van Mourik Broekmanweg 6, 2628 XE Delft, The Netherlands}
\cortext[cor1]{Corresponding author}

\begin{abstract}
In finite element methods (FEMs), the solution accuracy cannot be improved indefinitely because of the limited computer precision. We propose an innovative method to find the highest attainable accuracy (HAA). To this end, we validate the bound of the highest attainable accuracy for the second-order ordinal differential equations a priori. Based on the FEM method, element degree, we can extrapolate the discretization error when it converges at the analytical rate. As a result, a formula for the highest attainable accuracy is proposed. We apply our method to a one-dimensional Helmholtz equation in space. It shows that the highest attainable accuracy can be accurately predicted, and the CPU time required is much less compared with that only using $h$-refinements. 
\end{abstract}

\begin{keyword}
Finite Element Method (FEM), error estimation, optimal number of degrees of freedom, $hp$-refinement strategy.
\end{keyword}

\end{frontmatter}

\section{Introduction}

Many problems in engineering sciences and industry are modelled mathematically by initial-boundary value problems comprising systems of coupled, nonlinear partial and/or ordinary differential equations. These problems often consider complex geometries, with initial and/or boundary conditions that depend on measured data \cite{Kumar2016}. 
In some applications, not only the solution, but also its derivatives are of interest \cite{Kumar2016,carey1982derivative}.
For many problems of practical interest, analytical or semi-analytical solutions are not available, and hence one has to resort to numerical solution methods, such as the finite difference, finite volume, and finite element methods. The latter will be adopted throughout this paper and applied to one-dimensional boundary value problems.

The accuracy of the numerically obtained solution is influenced by many sources of errors \cite{ferziger2012computational}: firstly, errors in the set-up of the models, such as the simplification of the domain and governing equations and the approximation of the initial and boundary conditions; next, truncation errors due to the discretization of the computational domain and the use of basis functions for the function spaces defined on it; then, the iteration error resulting from the artificially controlled tolerance of iterative solvers; finally, the round-off error due to the adoption of finite-precision computer arithmetics, rather than exact arithmetics.
One tacitly assumes that most errors are well-balanced and/or negligibly small.
In particular, the round-off error is often ignored based on the argument that it will be `sufficiently small' if just IEEE-754 double-precision floating-point arithmetics \cite{zuras2008ieee} are adopted.
In this paper, the focus is on the overall discretization error due to truncation and round-off. In particular, we will show that the latter might very well have a significant influence on the overall accuracy and propose a practical strategy to balance both error contributors.

The discretization error strongly depends on the number of degrees of freedom (``DoFs"), denoted by $N_h^{(p)}$, which is a function of the mesh width $h$ and the approximation order $p$. The truncation error, denoted by ${E}_{\rm {T}}$, dominates the discretization error only when $N_h^{(p)}$ is not too large, and it decreases with increasing mesh resolution and element degree as it can be expected from finite element theory \cite{gockenbach2006understanding}. Based on this, the commonly used approaches to reduce the truncation error are to reduce the mesh width ($h$-refinement), increase the approximation order ($p$-refinement), or apply both strategies simultaneously ($hp$-refinement) \cite{guo1986hp}. 
The round-off error, denoted by ${E}_{\rm R}$, is, however, only negligible for moderately small values of $N_h^{(p)}$ and dominates the overall discretization error if more and more DoFs are employed \cite{Babuska2018Roundoff}. 
Consequently, for a particular approximation order $p$, by performing $h$-refinement, the best accuracy is obtained at the break-even point where the discretization error is the smallest. We denote the highest accuracy by ${E}_{\rm {min}}^{(p)}$ and the optimal number of DoFs by $N_{\rm opt}^{(p)}$.

While $N_{\rm opt}^{(p)}$ is typically impractically large if low(est)-order approximations are used, it can be very small if high-order approximations are adopted, which are nowadays becoming more and more popular, and make the results more prone to be polluted by round-off errors.
Despite this alarming observation, to the authorsâ€™ best knowledge, only very few publications address the impact of accumulated round-off errors on the overall accuracy of the final solution \cite{ling1984numerical,mou2017example} or take them into account explicitly in the error-estimation procedure {\cite{ainsworth1992procedure,kelly1983posteriori}}.
The general rule of thumb is still to perform as many $h$-refinements as possible considering the available computer hardware.

The aim of this paper is to systematically analyze the influence of the round-off error on the discretization error, for the solution, and its first and second derivative, and propose a practical approach for obtaining ${E}_{\rm {min}}^{(p)}$.
The scope is restricted to one-dimensional model problems, i.e. Poisson, diffusion and Helmholtz equations, for which both the standard finite element method (FEM) and the mixed FEM\cite{boffi2013mixed} are considered.
To assess the general applicability of the aforementioned approach, the following factors are investigated: the element degree over a wide range, first and second derivative of the solution, type of boundary conditions and method of implementing them, choice and configuration of the linear system solver, order of magnitude of the solution and its derivatives, and equation type.

The paper is organized as follows. The model problem, finite element formulation and numerical implementation are described in Section \ref{section_model_problem_FEM_formulation_numerical_implementation}. The general behavior of the discretization error and the approach to predict ${E}_{\rm {min}}^{(p)}$ are discussed in Section \ref{approach_finding_optimal_number_of_DoFs}. Numerical results for determining the offset of the round-off error are shown in Section \ref{section_error_constants}. The algorithm for realizing the approach is put forward in Section \ref{section_algorithm_application}, followed by its validation by a Helmholtz problem in Section \ref{section_validation}. The conclusions are drawn in Section \ref{paragraph on conclusion}.

\section{Model problem, finite element formulation and numerical implementation}	\label{section_model_problem_FEM_formulation_numerical_implementation}

\subsection{Model problem}

Consider the following one-dimensional second-order differential equation:
\begin{equation}
  -\left(d(x) u_x \right)_x + r(x)u(x) = f(x),\qquad x \in I = (0,1),	\label{1D_general_Helmholtz_equation}
\end{equation}
with $u$ denoting the unknown variable, which can either be real or complex, $f(x) \in L^2 (I)$ a prescribed right-hand side, and $d(x)$ and $r(x)$ continuous coefficient functions.
By choosing $d(x)=1$ and $r(x)=0$, Eq. (\ref{1D_general_Helmholtz_equation}) reduces to the Poisson equation; for $d(x)>0$ and not constant, when $r(x)=0$, the diffusion equation is found, and when $r(x) \neq 0$, we obtain the Helmholtz equation. 
The boundary conditions are $u(x)=g(x)$ on $\Gamma_D$ and $d(x)u_x=h(x)$ on $\Gamma_N$. Here, $\Gamma_D$ and $\Gamma_N$ are the boundaries where Dirichlet and Neumann boundary conditions are imposed, respectively.
In this paper, for all the equations investigated, the existence of the second derivative is guaranteed in the weak sense, i.e. $u \in H^2 (I)$.
% , see \cite{boffi2013mixed}.

\subsection{Finite element formulation} 	\label{FE formulation}

For convenience, we introduce the two inner products:
 \begin{subequations}
  \begin{align}
   (f_1(x), \,f_2(x) ) &= \int _I f_1(x) f_2(x) \, dx,	\\
   (g_1(x), \,g_2(x) )_{\Gamma} &= g_1(x_0) g_2(x_0).
  \end{align}
 \end{subequations}
where $f_1(x)$, $f_2(x)$, $g_1(x)$ and $g_2(x)$ are continuous functions defined on the unit interval $I$, $\Gamma$ denotes the boundary of $I$, and $x_0$ denotes the value of $x$ on $\Gamma$.

\subsubsection{The standard FEM}

The weak form of Eq. (\ref{1D_general_Helmholtz_equation}) is derived in \ref{derivation_weak_form_SM}. Imposing the Dirichlet boundary conditions strongly, the weak form reads:
\begin{equation}
\centering
\boxed{ 
\begin{aligned}
&\text{Weak~form}~ 1 ~~~~~~~~~\\
&\text{Find $u \in H _D^1 (I)$ such that:} \\
&({ \eta} _{ x }, \, du _{ x }  ) + (\eta, \, ru) = (\eta, \, f ) + (\eta, \, hn)_{\Gamma _N} \qquad \forall \eta \in H _{D0}^1 (I),\\
&\text{with} \\
&~~~~~~~~~~~~~H_{D} ^1 (I) = \{t \; | \; t \in H^1 (I), \; t = g \text{ on } \Gamma _D \},  \\
&~~~~~~~~~~~~H_{D0} ^1 (I) = \{t \; | \; t \in H^1 (I), \; t = 0 \text{ on } \Gamma _D\},\\
&\text{where } {n} \text{ is 1 at $x=1$, and $-1$ at $x=0$.}
\end{aligned}		\label{1D_general_SM_weak_form_Diri_strong} 
}
\end{equation}

Next, we approximate the exact solution $u_{\rm exc}$ by a linear combination of a finite number of basis functions:

\begin{equation}
 u_{\rm exc} \approx u_h^{(p)} = \sum _ {i=1} ^{m} u _{i} \varphi _{i}^{(p)}. \label{General_SM_u_approx}%
\end{equation}
Here, $\varphi _{i}^{(p)}$ are $C^0$-continuous Lagrange basis functions of degree $p$, denoted as $P_p$, with Gauss-Lobatto support points $x_j$, which feature the Kronecker-delta property, i.e. $\varphi _{i}^{(p)} (x_j)=\delta_{ij}$. The coefficients $u_i$ are the values of $u_h^{(p)}$ at the $\text{DoFs}$, as a direct consequence of the Kronecker-delta property of $\varphi _{i}^{(p)}$. The number of DoFs of $u_h^{(p)}$, denoted by $m$, equals $p \times t + 1$, where $t$ is the total number of the grid cells. 
Finally, taking the test function $\eta$ equal to $\varphi ^{(p)}_{k},~ k=1, \,2, \, \ldots , \, m$, we obtain
\begin{equation}
 A {U} = F,				\label{matrix equation std FEM}
\end{equation}
where $A$ is the stiffness matrix, $F$ the right-hand side and $U$ the discrete solution, i.e. the vector of the coefficients $u_i$.

\subsubsection{The mixed FEM}

As a first step, we introduce the auxiliary variable
\begin{subequations}
\begin{align}
   v(x) = - d(x)u_x, \label{Gene_MM_strong1} 
\end{align}  
allowing Eq. (\ref{1D_general_Helmholtz_equation}) to be rewritten as
\begin{align}
  -v_x - r(x)u(x) = -f(x).  \label{Gene_MM_strong2}
\end{align}	\label{1D_general_MM_2in1}%
\end{subequations}
Unlike the standard FEM, for the mixed FEM, the essential boundary conditions are imposed on $\Gamma _N$, and the natural boundary conditions on $\Gamma _D$.
The weak form of Eq. (\ref{1D_general_Helmholtz_equation}) using the mixed FEM, derived in \ref{derivation_weak_form_MM}, is given by:
\begin{subequations}
\begin{empheq}[box=\fbox]{align}
&\text{Weak~form}~ 2 ~~~~~~~~~\notag\\
&\text{Find $v \in H_{N}^1 (I)$ and $u \in L ^2 (I)$ such that:}	\notag\\
& ~~~~~~~\;(w, \, d^{-1}v) - (w_x, \,  u ) = -(w, \, g n)_{\Gamma_D} \qquad \forall w \in H_{N0}^1 (I), \label{1D_General_MM_weak_1}\\ 
& ~~~~~~~~~- (q, \, v_x) - (q, \, ru) = -(q, \, f) \qquad \forall q \in L ^2 (I), \label{1D_General_MM_weak_2}	\\
&    \text{with}\notag\\
& ~~~~~~~~~~~~~~~ H_{N} ^1 (I) = \{t \; | \; t \in H^1 (I), \; t = -h \text{ on } \Gamma _N \},  \notag\\
& ~~~~~~~~~~~~~\, H_{N0} ^1 (I) = \{t \; | \; t \in H^1 (I), \; t = 0 \text{ on } \Gamma _N\}.	\notag 
\end{empheq}
\label{1D_General_MM_weak_2in1}%
\end{subequations}
Next, we approximate the exact gradient $v_{\rm exc}$ and the exact solution $u_{\rm exc}$ by a linear combination of a finite number of basis functions:
\begin{subequations}
 \begin{align}
 v_{\rm exc} \approx v _h^{(p)} &= \sum _ {i=1} ^{n} v _{i} \varphi _{i}^{(p)},     \label{General_MM_var_approx1}  \\[3ex]
 u_{\rm exc} \approx u _h^{(p-1)} &= \sum\limits _ {j=1} ^{p} u _{cj} \psi _{j} ^{(p-1)} \text{ in cell }c, \text{ for } c=1,\,2, \, \ldots, \,t.  \label{General_MM_var_approx2}
\end{align}	\label{General_MM_var_approx}%
\end{subequations}
where $\varphi _{i}^{(p)}$ are of the same type of basis functions used in Eq. (\ref{General_SM_u_approx}), with coefficients $v_i$ the associated values of $v_h^{(p)}$ at the $\text{DoFs}$;
$\psi _{j} ^{(p-1)}$ are discontinuous Lagrange basis functions of degree $p-1$, denoted as $P_{p-1}^{\text{disc}}$, with coefficients $u_{c,j}$ the associated values of $u_h^{(p-1)}$ at the $\text{DoFs}$. 
This pair of elements will be referred to as $P_p/P_{p-1}^{\text{disc}}$.
Since the use of discontinuous basis functions, there are two independent $u_{c,j}$ at cell interfaces.
The number of DoFs for $v_h^{(p)}$, denoted by $n$, equals $p \times t + 1$, and the number of DoFs for $u_h^{(p-1)}$ equals $p \times t$. 
Finally, replacing the test functions $w$ and $q$ by $\varphi _{k}^{(p)} , ~{k} = 1, \,2, \, \ldots , \, p \times t + 1, $ and $ \psi _{e}^{(p-1)} ,~ {e} = 1, \,2, \, \ldots , \, p \times t$, respectively, the resulting coupled linear system of equations that has to be solved reads:
\begin{equation}
 \left[ \begin{array}{cc} M & B  \\ B^\top & 0 \end{array}\right] \left[ \begin{array}{cc} {V} \\ {U} \end{array}\right] =\left[ \begin{array}{cc} G \\ H \end{array}\right], \label{matrix equation mix FEM}
\end{equation}
where the mass matrix $M$, the discrete gradient operator $B$, and its transpose, the discrete divergence operator $B^\top$, are the components of the discrete left-hand side of Eqs. (\ref{1D_General_MM_weak_1})--(\ref{1D_General_MM_weak_2}), $G$ and $H$ are the components of the right-hand side, and $V$ and $U$ are the discrete first derivative and solution, i.e. the vectors of the coefficients $v_i$ and $u_{cj}$, respectively.

For the sake of readability, we will drop the superscript $(p)$, whenever the approximation order is clear from the context.

\subsection{Numerical implementation}

In what follows, we demonstrate how to obtain the numerical solution for Eq. (\ref{1D_general_Helmholtz_equation}) with specific coefficients and assess its quality. For the latter, both the error, obtained using the analytical solution or the finer numerical solution, and the order of convergence are investigated.

\subsubsection{Solution technique}

Unless stated otherwise, all results are computed in IEEE-754 double precision \cite{zuras2008ieee} using the deal.\rom{2} finite element code \cite{alzetta2018deal} that provides subroutines for creating the computational grid, building and solving the system of equations, and computing the error norms.

The computational mesh is obtained by globally refining a single element that covers the interval $I$, and the Dirichlet boundary conditions are imposed strongly unless stated otherwise.
The former means that, when the solution is real valued, using the standard FEM, the number of DoFs equals $2^{REF} \times p+1$ at the $REF$th refinement;
using the mixed FEM, the number of DoFs equals $2 \times 2^{REF} \times p+1$ at the $REF$th refinement.
For complex-valued problems, the above numbers double since deal.\rom{2} does not provide native support for complex-valued problems and, hence, all components need to be split into their real and imaginary parts.

To compute the occurring integrals, sufficiently accurate Gaussian quadrature formulas are used. 
Furthermore, unless stated otherwise, to solve the matrix equation, the UMFPACK solver \cite{davis2004algorithm}, which implements the multi-frontal LU factorization approach, is used as it results in relatively fast computations of the problems considered in this paper, and prevents the iteration errors for the iterative solvers. 

The derivatives, which are $u_{h,x}$ and $u_{h,xx}$ in the standard FEM and only $u_{h,xx}$ in the mixed FEM, are computed in the classical finite element manner, e.g. $u_{h,x} ^{(p-1)}=\sum\limits _{i=1}^m u_i\varphi_{i,x}^{(p)}$ yields an approximation to $u_x$ using standard FEM. 

\subsubsection{Error estimation}

For the numerical results $var_h$, where $var$ can be $u$, $u_x$ and $u_{xx}$, the discretization error measured in the $L_2$ norm is used. It is defined as
\begin{subequations}	\label{formula_abs_error}
\begin{align}		\label{formula_abs_error_analytical}
 E_{h} &= {\|var_{h}- {var}_{\rm exc}\|_{2}}
\end{align}
when the exact solution ${var}_{\rm exc}$ is available, or \cite{Runborg2012VerifyingNC}
\begin{align}		\label{formula_abs_error_numerical}
 {\widetilde {E_{h}}} &= {\|var_{h}- {var}_{h/2}\|_{2}}
\end{align}
otherwise,
\end{subequations}
where $var_{h/2}$ is the numerical solution computed on a mesh of grid size $h/2$. 
Furthermore, we compute the order of convergence from either $\log _2 \left( \frac{E_{h}}{E_{h/2}} \right)$ or $\log _2 \left( \frac{\widetilde {E_{h}}}{\widetilde {E_{h/2}}} \right)$, for which the theoretical value is one order higher than the approximation order\cite{gockenbach2006understanding}.


\section{Approach to finding the optimal number of DoFs}                 \label{approach_finding_optimal_number_of_DoFs}


\subsection{Theoretical basis}

The conceptual sketch of $E_h$ against $N_h$ in the log-log axes can be found in Fig.~\ref{sketch_discretization_error_one_p}, which is applicable to different variables for both the standard and mixed FEMs.
When $N_h$ is relatively small, $E_h$ may not decrease at the aforementioned theoretical order of convergence, denoted by the black circles, but it basically does when $N_h$ is relatively large, denoted by the green circles. During these two phases, $E_h$ is controlled by the truncation error $E_{\rm T}$, and it can be represented by 
\begin{equation}
 E_{h} \approx E_{\rm T} = \alpha_{\rm T}{N_{h}}^{-\beta_{\rm T}},		\label{formula_truncation_error}
\end{equation}
in the latter phase, where $\alpha_{\rm T}$ is the offset, and $\beta_{\rm T}$ the slope of the line approximating $E_h$.

For the increase part of $E_h$, denoted by the orange circles, it is controlled by the round-off error $E_{\rm R}$. Since the slope for the line approximating it tends to be fixed\cite{Babuska2018Roundoff,WalterFrei}, it can be represented by 
\begin{equation}
 E_{h} \approx E_{\rm R} = \alpha_{\rm R}{N_{h}}^{\beta_{\rm R}},		\label{formula_round-off_error}
\end{equation}
where $\alpha_{\rm R}$ is the offset and $\beta_{\rm R}$ the slope of the line approximating $E_h$. Moreover, since the values of the two constants are given or formulized in section \ref{section_error_constants}, $E_{\rm R}$ can be determined a priori.

 \begin{figure}[!ht]
 \centering
     \includegraphics[width=0.5\linewidth]{sketch_discretization_error_one_p.pdf}
     \caption{Conceptual sketch of the discretization error against the number of $\text{DoFs}$.}
     \label{sketch_discretization_error_one_p}
 \end{figure}

\subsection{Implementation process}           \label{section_strategy}

When $E_h$ starts to decrease at the analytical rate, for which $E_h$ and $N_h$ read ${E_{\rm c}}$ and ${N_{\rm c}}$, respectively, $\alpha_{\rm T}$ can be inverted by using
\begin{equation}
 \alpha_{\rm T} = {E_{\rm c}}/{N_{\rm c}}^{- \beta_{\rm T}}.		\label{formula_offset_truncation_error}
\end{equation}
After this point, both the development of $E_{\rm T}$ and $E_{\rm R}$ are known. Obviously, $N_{\rm opt}$ occurs when $E_{\rm T}+E_{\rm R}$ is the smallest. By solving
\begin{equation}
    \frac{d(E_{\rm T}+E_{\rm R})}{dN}=0,    \label{derivative_condition_N_opt}
\end{equation}
we can predict
\begin{subequations}
\begin{align}
 N_{\rm opt} = \left( \frac{\alpha_{\rm T} \beta_{\rm T}}{\alpha _{\rm R} \beta_{\rm R}} \right)^{\frac{1}{\beta_{\rm T} + \beta_{\rm R}}},
\end{align}
and hence, the highest attainable accuracy
\begin{align}
 E_{\rm min} = \alpha_{\rm T} {N_{\rm opt}}^{- {\beta _{\rm T}}}+\alpha_{\rm R} {N_{\rm opt}}^{{\beta _{\rm R}}}.
\end{align}
\end{subequations}

% \section{General behaviour of the discretization error}      \label{section_behaviour_discretization_error}

\section{Determination of the error constants in Fig.~\ref{sketch_discretization_error_one_p}}  	\label{section_error_constants}

To determine the constants $\alpha_{\rm R}$ and $\beta_{\rm R}$ in Fig.~\ref{sketch_discretization_error_one_p}, we investigate three benchmark equations using various element degrees, followed by a wide range of second-order differential equations using one particular element degree. Furthermore, we analyse the influence of the solution strategy and boundary condition.

\subsection{Benchmark equations}

The benchmark equations are shown in Table~\ref{benchmark one-dimensional equations}, for which the element degree ranges from 1 to 5.
                                                
\begin{table}[!ht]
\caption [sss] {Benchmark equations.}		% \footnotemark
\label{benchmark one-dimensional equations} 
\centering
 \begin{tabular}{|C{2.5cm}|C{4.2cm}|C{3.8cm}|C{4cm}|} \hline   
{} & {``Poisson''} & {``diffusion''} & {``Helmholtz''} \\ \hline
{$d(x)$} & {$1$} & $1+x$ & $(1+i) e^{-x}$  \\	\hline
{$r(x)$} & {0} & 0 & $2 e^{-x}$ \\	\hline
{$f(x)$} & {$-e^{- (x-1/2)^2} \left({4x^2 - 4x -1} \right)$}  & $-2 \pi \cos (2 \pi x) + 4 {\pi}^2 \sin (2 \pi x)(x+1)$ & 0 \\ \hline
{$\|f(x)\|_2$} & {1.60} & {42.99} & {0.00} \\	\hline
\multirow{2}{2cm}{\centering Boundary conditions} & {$u(0) = e^{-1/4}$} & $u(0)=0$& $u (0) = 1$ \\	\cline{2-4}
&$u(1) = e^{-1/4}$ & $u_x(1)=2 \pi$  &$ u_x(1) = 0$ \\	\hline
Analytical solution $u_{\text{exc}}$ & {$e^{- (x-1/2)^2}$} & $\sin (2 \pi x)$ & $a e^{(1+i) x} + (1-a) e^{-i x}$, $a=1/{((1-i) e^{1+2i}+1)}$ \\	\hline
{$\|u_{\text{exc}}\|_2$} & {0.92} & 0.71 & 1.26 \\	\hline
\end{tabular}
\end{table}

\newpage

For all the element degrees, $\alpha_{\rm R}$ and $\beta_{\rm R}$ for one particular variable are basically the same. The values of the former are shown in Fig.~\ref{alpha_R_benchmark}, which are as expected when using the double precision\cite{Alglib_custom}. The values of the latter are 2 using the standard FEM and 1 using the mixed FEM, which are taken as constants if not stated otherwise.

\begin{figure}[!ht]
\hspace{2.2cm}
% \centering
\begin{subfigure}[b]{0.4\textwidth}
\scalebox{0.9}{
\begin{tikzpicture} 
\begin{axis}
[
    ymode=log,    
    ymin=1e-20,
    ymax=1e-14,
    ytick={1e-20,1e-19,1e-18,1e-17,1e-16,1e-15,1e-14},
    yticklabels={1e-20,1e-19,1e-18,1e-17,1e-16,1e-15,1e-14},      
    legend style={nodes={scale=0.8},at={(0.45,0.2)},anchor=west},
    legend cell align={left},
    height=5cm,
    width=6cm,
    ylabel={$\alpha_{\rm R}$},
    ylabel style={at={(-0.2,0.5)}},     
    xtick={0,1,2,3,4},
    xticklabels={$u$, $u_x$, $u_{xx}$},
    xlabel={Variable},
    xlabel style={at={(0.5,-0.15)}},    
]
\addplot[black,mark=o,mark options={color=black,fill=black}] coordinates {(0,2.0e-17) (1,5.0e-17) (2,1.0e-15)};
\addplot[blue,mark=o,mark options={color=blue,fill=blue}] coordinates {(0,5.0e-17) (1,5.0e-17) (2,5.0e-16)};
\addplot[red,mark=o,mark options={color=red,fill=red}] coordinates {(0,2.0e-17) (1,2.0e-17) (2,5.0e-16)};
\legend{Poisson, diffusion, Helmholtz};
\end{axis}
\end{tikzpicture}
}
\caption{The standard FEM}
\label{alpha_R_benchmark_std}
\end{subfigure}
\hspace{-1.0cm}
\begin{subfigure}[b]{0.4\textwidth}
\scalebox{0.9}{
\begin{tikzpicture} 
\begin{axis}
[
    ymode=log,    
    ymin=1e-20,
    ymax=1e-14,
    ytick={1e-20,1e-19,1e-18,1e-17,1e-16,1e-15,1e-14},
    yticklabels={1e-20,1e-19,1e-18,1e-17,1e-16,1e-15,1e-14},        
    legend style={nodes={scale=0.8},at={(0.22,0.15)},anchor=west},
    legend cell align={left},
    height=5cm,
    width=6cm,
    ylabel={$\alpha_{\rm R}$},
    ylabel style={at={(-0.2,0.5)}},     
    xtick={0,1,2,3,4},
    xticklabels={$u$, $u_x$, $u_{xx}$} ,
    xlabel={Variable},
    xlabel style={at={(0.5,-0.15)}},    
]
\addplot[black,mark=o,mark options={color=black,fill=black}] coordinates {(0, 1.0e-19) (1, 5.0e-17) (2, 2.0e-16)};
\addplot[blue,mark=o,mark options={color=blue,fill=blue}] coordinates {(0, 1.0e-19) (1, 1.0e-17) (2, 5.0e-15)};
\addplot[red,mark=o,mark options={color=red,fill=red}] coordinates {(0,1.0e-17) (1,1.0e-17) (2,2.0e-16)};
% \legend{Dirichlet/Dirichlet, Dirichlet/Neumann};
\end{axis}
\end{tikzpicture}
}
\caption{The mixed FEM}
\label{alpha_R_benchmark_mix}
\end{subfigure}
\caption{$\alpha_{\rm R}$ for the benchmark equations.}
\label{alpha_R_benchmark}
\end{figure}


In addition, as that shown in Fig.~\ref{sketch_discretization_error_one_p}, $\beta_{\rm T}$ can be reached fast: for the benchmark Poisson equation, when the approximation order is 3, the development of the order of convergence is shown in Table~\ref{evolution_convergence_order_sample_equations}.

\begin{table}[!ht]
\caption[sss]{Evolution of order of convergence for the benchmark Poisson equation.}
\label{evolution_convergence_order_sample_equations}
\centering
%\hspace{1.5cm}
\begin{subtable}{0.4\textwidth}
\caption{The standard FEM}
 \begin{tabular}{c c c c} \hline
\multirow{2}{*}{\makecell{\# of \\refinements}} & \multicolumn{3}{c}{Order of convergence} \\ \cline{2-4}
 & $u$ & $u_x$ & $u_{xx}$ \\	\hline
2 & 3.97 & 4.02 & 3.87 \\ 
3 & 3.99 & 4.00 & 3.98 \\ 
4 & 4.00 & 4.00 & 4.00 \\ \hline
\end{tabular}
\end{subtable}
\quad
%\centering
\begin{subtable}{.4\textwidth}
\caption{The mixed FEM}
\begin{tabular}{c c c c} \hline
\multirow{2}{*}{\makecell{\# of \\refinements}} & \multicolumn{3}{c}{Order of convergence} \\ \cline{2-4}
 & $u$ & $u_x$ & $u_{xx}$ \\	\hline
2 & 3.96 & 4.02 & 3.86 \\ 
3 & 3.99 & 4.00 & 3.98 \\ 
4 & 4.00 & 4.00 & 4.00 \\ \hline
\end{tabular}
\end{subtable}
\end{table}

\subsection{General second-order differential equations}	    \label{section_scaling}

First, to cover a wide range of $\|u_{\rm exc}\|_2$, together with $\|f\|_2$, for the Poisson equation, we investigate the cases shown in Table \ref{scaling_cases_Poisson}, for which the distribution of $\|u_{\rm exc}\|_2$ and $\|f\|_2$ for Cases 1--4 can be found in Fig.~\ref{l2_norm_u_f}. Second, we investigate various $d(x)$ shown in Table~\ref{d_diffusion_equations} for the diffusion equations with $u=e^{-{(x-1/2)^2}}$. Last, we consider $r(x)$ from the first five cases of $d(x)$ in Table~\ref{d_diffusion_equations} for the Helmholtz equations with $u=e^{-{(x-1/2)^2}}$ and $d(x)=1$. Specifically, we restrict ourselves to $P_2$ and $P_4/P_3^{\rm disc}$ elements, and only Dirichlet boundary conditions are considered. 

\begin{table}[!ht]
\centering
\caption [w]{Settings of the Poisson equations with various $\|u_{\rm exc}\|_2$ and $\|f\|_2$.} 
\label{scaling_cases_Poisson}
 \begin{tabular}{c c c c} \hline      
Case & $f(x,c)$ & $u_{\text{exc}}(x,c)$ & $c$ \\ \hline
1 & $\sin (2 \pi cx)$ & ${(2 \pi c)}^{-2} \sin (2 \pi cx)$ & \multirow{2}{*}{1e-2, 1e-1, 1e0, 1e1, 1e2} \\ \cline{1-3}
2 & $(2 \pi c) \sin (2 \pi c x)$ & ${(2 \pi c)}^{-1} \sin (2 \pi cx)$ &  \\ \hline
3 & $\sin (2 \pi c x) +1$ & ${(2 \pi c)}^{-2}\sin (2 \pi c x)-\frac{x^2}{2}$ & \multirow{4}{*}{1e-4, 1e-2, 1e0, 1e2, 1e4} \\ \cline{1-3}
4 & $\makecell{-e^{-{c}{(x-1/2)^2}} \cdot \\ \left({4{c}^2(x-1/2)^2 -2c} \right)}$ & $e^{-{c}{{(x-1/2)^2}}}$ &  \\ \cline{1-3}
5 & $0$ & ${c}^{-1} x$ &  \\ \hline
\end{tabular}
\end{table}

\begin{figure}[!ht]
\centering
    \includegraphics[width=0.5\linewidth]{../3_figure_plot/3_l2_norm_u_f/l2_norm_u_f.pdf}
    \caption{Distribution of $\|u_{\rm exc}\|_2$ and $\|f\|_2$ for the Poisson equations in Table~\ref{scaling_cases_Poisson}.}
    \label{l2_norm_u_f}
\end{figure}

\begin{table}[!ht]
\centering
\caption [w]{Various $d(x)$ for the diffusion equations.} 
\label{d_diffusion_equations}
 \begin{tabular}{c c c c c c} \hline
$\#$ &$d(x)$ & $\|d(x)\|_2$ & $\#$ &$d(x)$ & $\|d(x)\|_2$ \\ \hline
1 & 0.01 & 0.01 & 7 & $1+\sin(10x)$ & 1.14 \\ \hline
2 & 0.1 & 0.1 & 8 & $1+\sin(100x)$ & 1.06 \\ \hline
3 & 1 & 1 & 9 & $1+x$ & 1.5 \\ \hline
4 & 10 & 10 & 10 & $1+10x$ & 6.7 \\ \hline
5 & 100 & 100 & 11& $1+100x$ & 58.6 \\ \hline
6 & $1+\sin(x)$ & 1.23 & & &  \\ \hline
\end{tabular}
\end{table}

\newpage

For the three types of equations, $\alpha_{\rm R}$ for different variables are shown in Fig.~\ref{py_offset_summary_Pois} -- Fig.~\ref{py_offset_summary_Helm}, in which the relations between the upper bound of $\alpha_{\rm R}$ and the $x$ axis are denoted.
In detail, for the Poisson equations, $\alpha_{\rm R}$ increases linearly with the $x$ axis; for the diffusion equations, $\alpha_{\rm R}$ increases linearly with $d(x)$ for $d(x)u_x$ and $(d(x)u_x)_x$ using the mixed FEM, while it is relatively independent of $d(x)$ in other scenarios; for the Helmholtz equations, $\alpha_{\rm R}$ is independent of $r(x)$.
To summarize, the formula of $\alpha_{\rm R}$ can be expressed as that shown in Table~\ref{relation_alpha_R_l2_norm_u_du}.

%\newpage
\begin{figure}[!ht]
	\hspace{2.5cm}
    \begin{subfigure}{5.4cm}
        \includegraphics[width=1.0\linewidth]{../3_figure_plot/2_offset_summary/py_offset_summary_Pois_sm.pdf}
        \caption{The standard FEM}
        \label{py_offset_summary_Pois_sm}
    \end{subfigure}
    \hspace{-0.2cm}
    \begin{subfigure}{5.4cm}
        \includegraphics[width=1.0\linewidth]{../3_figure_plot/2_offset_summary/py_offset_summary_Pois_mm.pdf}
        \caption{The mixed FEM}
        \label{py_offset_summary_Pois_mm}
    \end{subfigure}
\caption{$\alpha_{\rm R}$ for the Poisson equations in Table~\ref{scaling_cases_Poisson}.}
\label{py_offset_summary_Pois}
\end{figure}


\begin{figure}[!ht]
	\hspace{2.5cm}
    \begin{subfigure}{5.4cm}
        \includegraphics[width=1.0\linewidth]{../3_figure_plot/2_offset_summary/py_offset_summary_diff_sm.pdf}
        \caption{The standard FEM}
        \label{py_offset_summary_diff_sm}
    \end{subfigure}
    \hspace{-0.2cm}
    \begin{subfigure}{5.4cm}
        \includegraphics[width=1.0\linewidth]{../3_figure_plot/2_offset_summary/py_offset_summary_diff_mm.pdf}
        \caption{The mixed FEM}
        \label{py_offset_summary_diff_mm}
    \end{subfigure}
\caption{$\alpha_{\rm R}$ for the diffusion equations with $u=e^{-{(x-1/2)^2}}$ and various $\|d\|_2$ in Table~\ref{d_diffusion_equations}.}
\label{py_offset_summary_diff}
\end{figure}

\begin{figure}[!ht]
	\hspace{2.5cm}
    \begin{subfigure}{5.4cm}
        \includegraphics[width=1.0\linewidth]{../3_figure_plot/2_offset_summary/py_offset_summary_Helm_sm.pdf}
        \caption{The standard FEM}
        \label{py_offset_summary_Helm_sm}
    \end{subfigure}
    \hspace{-0.2cm}
    \begin{subfigure}{5.4cm}
        \includegraphics[width=1.0\linewidth]{../3_figure_plot/2_offset_summary/py_offset_summary_Helm_mm.pdf}
        \caption{The mixed FEM}
        \label{py_offset_summary_Helm_mm}
    \end{subfigure}
\caption{$\alpha_{\rm R}$ for the Helmholtz equations with $u=e^{-{(x-1/2)^2}}$, $\|d\|_2=1$ and $r(x)$ taken from the first five cases of $d(x)$ in Table~\ref{d_diffusion_equations}.}
\label{py_offset_summary_Helm}
\end{figure}



\begin{table}[!ht]
\captionof{table}{Expressions of $\alpha_{\rm R}$ for the second-order differential equations.}
\hspace{2.5cm}
\begin{subtable}{0.4\textwidth}
\caption{The standard FEM}
\begin{tabular}{l l}
\hline
$u$ & 2e-17 $\times \|u\|_2$ \\ \hline 
$u_x$ & 5e-17 $\times \|u\|_2$ \\ \hline
$u_{xx}$ & 1e-15 $\times \|u\|_2$ \\ \hline
\end{tabular}
\end{subtable}
\hspace{-0.5cm}
\begin{subtable}{.4\textwidth}
\caption{The mixed FEM}
\begin{tabular}{l l l l}
\hline
$u$ & 5e-17 $\times \|u\|_2$ \\ \hline 
$d(x)u_x$ & 2e-16 $\times \|d(x)\|_2 \|u\|_2$ \\ \hline
$(d(x)u_x)_x$ & 5e-16 $\times \|d(x)u_x\|_2$ \\ \hline
\end{tabular}
\end{subtable}
\label{relation_alpha_R_l2_norm_u_du}
\end{table}


\newpage
\subsection{Sensitivity analysis}       \label{section_sensitivity}

We focus on the benchmark Poisson equation and the approximation order for the variable of interest is 3.

\subsubsection{Solution strategy}		\label{section_solver}

The alternative solution method to the UMFPACK solver is the iterative Conjugate Gradient (CG) method\cite{ginsburg1963cg}, which is applied when the left-hand side is symmetric and positive definite. We focus on the tolerance of the CG solver: the iteration stops when the norm of the residual is smaller than it. We furthermore denote the parameter in it by $tol_{prm}$.

For the standard FEM, the CG method can be applied directly. However, for the mixed FEM, since the left-hand side of Eq.~(\ref{matrix equation mix FEM}) is indefinite, it is applied after segregating Eq.~(\ref{matrix equation mix FEM}) based on the Schur complement, which results in
\begin{subequations}
 \begin{align}
  B^{\top} M^{-1} B U &= B^{\top} M^{-1} G - H, 	\label{schur_complement_solution} \\
  MV&=G-BU.						\label{schur_complement_gradient}
\end{align}						\label{schur_complement_solu_grad}%
\end{subequations}
In the solution process of Eq.~(\ref{schur_complement_solu_grad}), where Eq. (\ref{schur_complement_solution}) is solved in the first place to obtain $U$ and then it is substituted into Eq. (\ref{schur_complement_gradient}) to obtain $V$, the CG solver can be used for the left-hand side being either $B^{\top}M^{-1}B$ (Schur complement) or $M$. In particular, we investigate the former while the UMFPACK solver is used partly for the left-hand side being $M$.  

The evolution of the discretization error for various $tol_{prm}$ in comparison with that using the UMFPACK solver is shown in Fig.~\ref{py_bench_Pois_error_solution_strategy}. Note that, $\alpha_{\rm R}$ using the UMFPACK solver for the mixed FEM is smaller than the value shown in Table~\ref{relation_alpha_R_l2_norm_u_du}.
It shows that the CG solver introduces iteration errors when $tol_{prm}$ is less strict using the standard FEM, while the UMFPACK solver yields by far the most accurate results using the mixed FEM. This proves the correctness of choosing the UMFPACK solver to obtain higher accuracy. 

\begin{figure}[!ht]
	\centering
    \begin{subfigure}{5.5cm}
        \includegraphics[width=1.0\linewidth]{../3_figure_plot/4_solution_strategy/py_error_comparison_solution_strategy_SM_solu.pdf}
        \caption{The standard FEM}
        \label{py_bench_Pois_SM_error_solution_strategy_solu}
    \end{subfigure}
    \hspace{-0.2cm}
    \begin{subfigure}{5.5cm}	                		 	
        \includegraphics[width=1.0\linewidth]{../3_figure_plot/4_solution_strategy/py_error_comparison_solution_strategy_MM_solu.pdf}
        \caption{The mixed FEM}
        \label{py_bench_Pois_MM_error_solution_strategy_solu}
    \end{subfigure}
\caption{Comparison of the errors using the CG solver and the UMFPACK solver.}
\label{py_bench_Pois_error_solution_strategy}
\end{figure}

\newpage

\subsubsection{Boundary conditions}	\label{section_BC}

In this section, the influence of boundary condition types on the round-off error are investigated.
The Dirichlet boundary condition at the left boundary ($x=0$) is kept while the Dirichlet boundary condition at the right boundary ($x=1$) has been replaced by the Neumann boundary condition $u_x (1) = -e^{-1/4}$, leading to the same solution and derivative profiles. 


% \newpage
\paragraph{The standard FEM}
Using the standard FEM, the offsets $\alpha_{\rm R}$ for the two types of boundary conditions are depicted in Fig.~\ref{boundary_type_benchmark_Poisson_std}. 
For the Dirichlet/Neumann boundary condition, the offsets $\alpha_{\rm R}$ for $u$ and $u_x$ are slightly larger than that for the Dirichlet/Dirichlet boundary condition by a factor of 3.5 and 2, respectively. The offsets $\alpha_{\rm R}$ for $u_{xx}$ are identical for the two types of boundary conditions.

\paragraph{The mixed FEM}
Using the mixed FEM, the offsets $\alpha_{\rm R}$ for the two types of boundary conditions are depicted in Fig.~\ref{boundary_type_benchmark_Poisson_mix}.
As can be seen, the type of boundary conditions plays a more important role for $\alpha_{\rm R}$ for the solution than $\alpha_{\rm R}$ for other variables.


\begin{figure}[!ht]
\hspace{2.2cm}
% \centering
\begin{subfigure}[b]{0.4\textwidth}
\scalebox{0.9}{
\begin{tikzpicture} 
\begin{axis}
[
    ymode=log,    
    ymin=1e-20,
    ymax=1e-15,
    ytick={1e-20,1e-19,1e-18,1e-17,1e-16,1e-15},
    yticklabels={1e-20,1e-19,1e-18,1e-17,1e-16,1e-15},      
    legend style={nodes={scale=0.8},at={(0.22,0.15)},anchor=west},
    legend cell align={left},
    height=5cm,
    width=6cm,
    ylabel={$\alpha_{\rm R}$},
    ylabel style={at={(-0.2,0.5)}},     
    xtick={0,1,2,3,4},
    xticklabels={$u$,$u_x$, $u_{xx}$, $4$, ${5}$},
    xlabel={Variable},
    xlabel style={at={(0.5,-0.1)}},    
]
\addplot[black,mark=diamond,mark options={color=black,fill=black}] coordinates {(0,2.0e-17) (1,5.0e-17) (2,5.0e-16)};
\addplot[green,mark=diamond,mark options={color=green,fill=green}] coordinates {(0,7.0e-17) (1,1.0e-16) (2,5.0e-16)};
\legend{Dirichlet/Dirichlet, Dirichlet/Neumann};
\end{axis}
\end{tikzpicture}
}
\caption{The standard FEM}
\label{boundary_type_benchmark_Poisson_std}
\end{subfigure}
\hspace{-1.0cm}
\begin{subfigure}[b]{0.4\textwidth}
\scalebox{0.9}{
\begin{tikzpicture} 
\begin{axis}
[
    ymode=log,    
    ymin=1e-20,
    ymax=1e-15,
    ytick={1e-20,1e-19,1e-18,1e-17,1e-16,1e-15},
    yticklabels={1e-20,1e-19,1e-18,1e-17,1e-16,1e-15},        
    legend style={nodes={scale=0.8},at={(0.22,0.15)},anchor=west},
    legend cell align={left},
    height=5cm,
    width=6cm,
    ylabel={$\alpha_{\rm R}$},
    ylabel style={at={(-0.2,0.5)}},     
    xtick={0,1,2,3,4},
    xticklabels={$u$,$u_x$, $u_{xx}$, $4$, ${5}$},
    xlabel={Variable},
    xlabel style={at={(0.5,-0.1)}},    
]
\addplot[black,mark=square,mark options={color=black,fill=black}] coordinates {(0, 5.0e-20) (1, 6.0e-17) (2, 2.0e-16)};
\addplot[green,mark=square,mark options={color=green,fill=green}] coordinates {(0, 3.0e-17) (1, 1.0e-17) (2, 2.0e-16)};
\end{axis}
\end{tikzpicture}
}
\caption{The mixed FEM}
\label{boundary_type_benchmark_Poisson_mix}
\end{subfigure}
\caption{Comparison of the errors for imposing Dirichlet/Dirichlet and Dirichlet/Neumann boundary conditions.}
\label{boundary_type_benchmark_Poisson}
\end{figure}


In summary, $\alpha_{\rm R}$ are relatively independent of the variations in the type of boundary conditions and the method Dirichlet boundary conditions are implemented, which is an important prerequisite for our a posteriori refinement strategy to be applicable for a wide range of problems.

To conclude the sections on sensitivity analysis, the factors that cannot be mitigated are the tolerances for the iterative linear solver, that can be mitigated are the order of magnitude, and that are relatively irrelevant are the boundary conditions.


\section{Algorithm and its application}		\label{section_algorithm_application}

Based on the approach given in section \ref{approach_finding_optimal_number_of_DoFs} and error constants validated in section \ref{section_error_constants}, we first introduce a novel algorithm, and then use it to determine $E_{\rm min}$.

\subsection{Algorithm}
The default and custom settings of the algorithm are given in Table \ref{settings_algorithm}.

\begin{table}[!ht]
\captionof{table}{Settings of the algorithm.}
\label{settings_algorithm}
  \centering
  \begin{tabular}{lL{5cm}L{6cm}}
    \toprule
    Item & Default & Custom  \\
    \midrule
    Problem & - & \tabitem the differential equation to be solved \\
     &  & \tabitem its associated boundary conditions \\\hline
    Grid & \tabitem initial number of vertices: 2 & - \\
     & \tabitem refined globally afterwards &  \\\hline
    FEM & \tabitem the maximum $N_h$, denoted by $N_{\rm max}$, : $10^8$ & \tabitem standard or mixed formulation \\
    & \tabitem Dirichlet boundary conditions are imposed strongly & \tabitem an ordered array of element degrees $\{p_{\min}, \ldots, p_{\rm max}\}$ \\\hline
    Computer precision & IEEE-754 double precision & - \\\hline
    Solver & UMFPACK & - \\\hline
    $var$ & - & \tabitem chosen from $\{u,~u_x,~u_{xx}\}$ \\     
    & & \tabitem error tolerance $tol_{var}$ \\     
    \bottomrule
  \end{tabular}
\end{table}

% \newpage
Furthermore, the following coefficients are used.
\begin{itemize}
  \renewcommand\labelitemi{--}
  \item a minimal number of $h$-refinements before `\textit{NORMALIZATION}' and carrying out `\textit{PREDICTION}', denoted by $REF_{\rm min}$, with the following default values:
  \begin{equation}
  \begin{aligned}
      REF_{\rm min} &=
      \begin{cases*}
	9-p & for p $<$ 6, \\
	4 & otherwise.
      \end{cases*}
  \end{aligned}
  \end{equation} 
  We choose this parameter mainly because the error might increase, or decrease faster than the theoretical order of convergence for coarse refinements, especially for lower-order elements.
%   \item a stopping criterion $c_s$ for seeking the scaling factor $\|var_{\rm exc}\|_{2}$ in Table~\ref{scaling schemes std and mix FEM}, its value is 0.001 by default. We choose this parameter because the analytical solution does not exist for most practical problems.
  \item a relaxation coefficient $c_r$ for seeking the theoretical order of convergence, with the following default values: 
    \begin{equation}
    \begin{aligned}
	c_r &=
	\begin{cases*}
	  0.9 & for p $<$ 4, \\
	  0.7 & for 4 $\leqslant$ p $<$ 10, \\
	  0.5 & otherwise.
	\end{cases*}
    \end{aligned}
    \end{equation}
  \item $\alpha _{\rm R}$ in Table \ref{relation_alpha_R_l2_norm_u_du}.    
\end{itemize}

% \newpage
The procedure of our algorithm consists of four steps, which are explained below:

\paragraph{Step-1} `\textit{INPUT}'. In this step, the custom input has to be provided.
\paragraph{Step-2} `\textit{NORMALIZATION}'. The function of this step is to find the scaling factor to normalize problems of different orders of magnitude for the variable. The specific procedure can be found in Algorithm \ref{algo_scaling_factor}, where elements of degree $p_{\rm min}$ are used. 

\vspace{0.2cm}
\begin{algorithm}[H]
\caption{NORMALIZATION}
\label{algo_scaling_factor}
\While{$N_h<N_{\rm max}$}
{
    \eIf{$\left|\frac{\|var_{h}\|_{2} - \|var_{2h}\|_{2}}{\|var_{h}\|_{2}} \right| < c_s$}
    {
        $\|var_{\rm exc}\|_{2}$ $\gets$ $\|var_{h}\|_{2}$\;
        break\;
    }
    {
        $h$ $\gets$ $h/2$\;
        calculate $\|var_h\|_{2}$ using Eq. (\ref{formula_abs_error_analytical}) without scaling\;    
    }
}
\end{algorithm}
                                                                   
\paragraph{Step-3} `\textit{PREDICTION}'. This step finds $E_{\rm min}$ for each $var$ and $p$ of interest, as illustrated in Fig.~\ref{sketch_discretization_error_one_p}.
The procedure for carrying out this step can be found in Algorithm \ref{block_PREDICTION}.

\vspace{0.2cm}
\begin{algorithm}[H]
\caption{PREDICTION}			% Seeking the analytical order of convergence Predicting $N_{\rm opt}$ and $E_{\rm min}$
\label{block_PREDICTION}
    \While{$\widetilde {E_{h}}>E_{\rm R}$ \textbf{\textup{and}} $N_h<N_{\rm max}$}
    {
        $\widetilde{Q}$ $\gets$ $\log _2 \left( {\widetilde {E_{2h}}}/{\widetilde {E_{h}}} \right)$\;
        \eIf
        {
            $\widetilde{Q} \geqslant \beta_{\rm T} \times c_r$
        }
        {
            $N_{\rm c} \gets N_h$\;
            $E_{\rm c} \gets \widetilde {E_{h}}$\;
            $\alpha_{\rm T}$ $\gets$ ${E_{\rm c}}/{N_{\rm c}}^{- \beta_{\rm T}}$\;
            $N_{\rm opt} \gets \left( \frac{\alpha_{\rm T} \beta_{\rm T}}{\alpha _{\rm R} \beta_{\rm R}} \right)^{\frac{1}{\beta_{\rm R} + \beta_{\rm T}}}$\;
            $E_{\rm min} \gets \alpha_{\rm T} {N_{\rm opt}}^{- {\beta _{\rm T}}} + \alpha_{\rm R} {N_{\rm opt}}^{{\beta _{\rm R}}}$\;

        }
        {
            $h$ $\gets$ $h/2$\;
            calculate $\widetilde {E_{h}}$ using Eq.~(\ref{formula_abs_error_numerical}) with proper scaling schemes\;
        }
	}    
\end{algorithm}

\paragraph{Step-4} `\textit{OUTPUT}'. In this step, we output $E_{\rm min}$ obtained from $Step$-3.

\subsection{Application}		\label{section_validation}

We validate the algorithm by using the following Helmholtz problem\citep{chernetsky2010effect}:
\begin{equation}
  \left((0.01+x)(1.01-x) u_x \right)_x -(0.01i) u(x) = 1.0,\qquad x \in I = (0,1),	\label{1D_Helmholtz_equation_application}
\end{equation}
with homogeneous Dirichlet and Neumann boundary conditions imposed as follows: $u(0)=0$ and $u_x(1)=0$.

Both the standard FEM and the mixed FEM are investigated, and the element degree $p$ has a range of $\{1, 2, \ldots, 5\}$.

Using the prediction approach and the brute-force approach, $E_{\rm min}$ are compared in Fig.~\ref{E_min_application}. As can be seen, $E_{\rm min}$ can be predicted correctly.


\begin{figure}[!ht]
	\hspace{1cm}
    \begin{subfigure}{5.5cm}
        \includegraphics[width=1.2\linewidth]{../3_figure_plot/6_comparison_brute-force_prediction/py_accuracy_comparison_dofinder_sm.pdf}
        \caption{The standard FEM}
        \label{py_bench_Pois_SM_error_solution_strategy_solu}
    \end{subfigure}
    \hspace{0.8cm}
    \begin{subfigure}{5.5cm}	                		 	
        \includegraphics[width=1.2\linewidth]{../3_figure_plot/6_comparison_brute-force_prediction/py_accuracy_comparison_dofinder_mm.pdf}
        \caption{The mixed FEM}
        \label{py_bench_Pois_MM_error_solution_strategy_solu}
    \end{subfigure}
\caption{Comparison of the errors using the CG solver and the UMFPACK solver.}
\label{py_bench_Pois_error_solution_strategy}
\end{figure}


\begin{figure}[!ht]
\hspace{0.0cm}
\begin{subfigure}[b]{0.35\textwidth}
\scalebox{0.9}{
\begin{tikzpicture} 
\begin{axis}
[
    width=6cm,
    height=5cm,
    xmin=-0.5,
    xmax=4.5,
    ymode=log,
    ymin=1e-16,
    ymax=1,
    ytick={1e-16, 1e-12, 1e-8, 1e-4, 1e0},
    yticklabels={1e-16, 1e-12, 1e-8, 1e-4, 1e0}, 
    ylabel={$E_{\min}$}, 
    ylabel style={at={(-0.18,0.5)}},  
    xtick={0,1,2,3,4},
    xticklabels={$1$, $2$, $3$, $4$, ${5}$},
    xlabel={$p$},
    xlabel style={at={(0.5,-0.12)}}, 
    legend style={nodes={scale=0.9}},
    legend cell align={left}
]
\addplot[black,mark=pentagon,mark options={color=black,fill=black}] coordinates {(0,2.1e-25)};
\addplot[black,mark=Mercedes star,mark options={color=black,fill=black}] coordinates {(0,2.1e-25)};

\addplot[blue,mark=pentagon,mark options={color=blue,fill=blue}] coordinates {(0,1.6e-7) (1,8.7e-9) (2,1.6e-9) (3,4.9e-10) (4,4.1e-10)}; 
\addplot[blue,mark=Mercedes star,mark options={color=blue,fill=blue}] coordinates {(0,3e-7) (1,1.2e-8) (2,6.4e-10) (3,1.05e-10) (4,4.7e-10)}; 

\addplot[red,mark=pentagon,mark options={color=red,fill=red}] coordinates {(0,1.06e-8) (1,7.05e-11) (2,7.13e-12) (3,1.47e-12) (4,8.27e-13)}; 
\addplot[red,mark=Mercedes star,mark options={color=red,fill=red}] coordinates {(0,1.0e-8) (1,1.35e-11) (2,1.02e-11) (3,3.9e-12) (4,2.16e-13)}; 
\addplot[color=black, dashed] coordinates {(-0.5, 1e-9) (4.5, 1e-9)};
\legend{Prediction,Brute-force};
\end{axis}
\end{tikzpicture}
}
\vspace{-0.2cm}
\caption{Solution}
\end{subfigure}
\hspace{-0.7cm}
\begin{subfigure}[b]{0.35\textwidth}
\scalebox{0.9}{
\begin{tikzpicture} 
\begin{axis}
[
    width=6cm,
    height=5cm,
    xmin=-0.5,
    xmax=4.5,
    ymode=log,
    ymin=1e-16,
    ymax=1,
    ytick={1e-16, 1e-12, 1e-8, 1e-4, 1e0},
    yticklabels={1e-16, 1e-12, 1e-8, 1e-4, 1e0}, 
    ylabel={$E_{\min}$}, 
    ylabel style={at={(-0.18,0.5)}},  
    xtick={0,1,2,3,4},
    xticklabels={$1$, $2$, $3$, $4$, ${5}$},
    xlabel={$p$},
    xlabel style={at={(0.5,-0.12)}}, 
    legend style={nodes={scale=0.9}},
    legend cell align={left}    
]
\addplot[blue,mark=pentagon,mark options={color=blue,fill=blue}] coordinates {(0,1.3e-4) (1,1.9e-6) (2,1.5e-7) (3,2.7e-8) (4,9.7e-9)}; 
\addplot[blue,mark=Mercedes star,mark options={color=blue,fill=blue}] coordinates {(0,1.2e-4) (1,1.2e-6) (2,3.8e-8) (3,2.6e-8) (4,3.0e-9)}; 

\addplot[red,mark=pentagon,mark options={color=red,fill=red}] coordinates {(0,5.47e-10) (1,4.62e-11) (2,1.12e-11) (3,4.11e-12) (4,2.21e-12)}; 
\addplot[red,mark=Mercedes star,mark options={color=red,fill=red}] coordinates {(0,1.57e-10) (1,4.56e-12) (2,1.15e-11) (3,4.2e-12) (4,3.91e-13)}; 
\addplot[color=black, dashed] coordinates {(-0.5, 1e-9) (4.5, 1e-9)};
\end{axis}
\end{tikzpicture}
}
\vspace{-0.2cm}
\caption{First derivative}
\end{subfigure}
\hspace{-0.7cm}
\begin{subfigure}[b]{0.35\textwidth}
\scalebox{0.9}{
\begin{tikzpicture} 
\begin{axis}
[
    width=6cm,
    height=5cm,
    xmin=-0.5,
    xmax=4.5,
    ymode=log,
    ymin=1e-16,
    ymax=1,
    ytick={1e-16, 1e-12, 1e-8, 1e-4, 1e0},
    yticklabels={1e-16, 1e-12, 1e-8, 1e-4, 1e0}, 
    ylabel={$E_{\min}$}, 
    ylabel style={at={(-0.18,0.5)}},  
    xtick={0,1,2,3,4},
    xticklabels={$1$, $2$, $3$, $4$, ${5}$},
    xlabel={$p$},
    xlabel style={at={(0.5,-0.12)}}, 
    legend style={nodes={scale=0.9}},
    legend cell align={left}
]
\addplot[blue,mark=pentagon,mark options={color=blue,fill=blue}] coordinates {(0) (1,1.66e-2) (2,1.71e-4) (3,1.3e-5) (4,2.46e-6)}; 
\addplot[blue,mark=Mercedes star,mark options={color=blue,fill=blue}] coordinates {(0) (1,1.6e-2) (2,1.7e-4) (3,1.3e-5) (4,2.5e-6)}; 

\addplot[red,mark=pentagon,mark options={color=red,fill=red}] coordinates {(0,4.25e-6) (1,2.07e-8) (2,1.70e-9) (3,3.75e-10) (4,1.45e-10)}; 
\addplot[red,mark=Mercedes star,mark options={color=red,fill=red}] coordinates {(0,5e-6) (1,5.36e-9) (2,1.41e-9) (3,5.33e-10) (4,7.29e-11)}; 
\addplot[color=black, dashed] coordinates {(-0.5, 1e-9) (4.5, 1e-9)};
\end{axis}
\end{tikzpicture}
}
\vspace{-0.2cm}
\caption{Second derivative}
\end{subfigure}
\caption{Comparison of $E_{\rm min}$ for Eq. (\ref{1D_Helmholtz_equation_application}) using the algorithm and the brute-force refinement. The blue color denotes the standard FEM, and the red color denotes the mixed FEM.}
\label{E_min_application}
\end{figure}

The CPU time required by the prediction approach (PRED) and the brute-force approach (BF) is shown in Fig.~\ref{CPU_algorithm_brute_force}. Next to time PRED, and the computation time for the optimal grid (PRED+) using the prediction approach is also given.
As can be seen, both time BF and time PRED+ decrease with increasing element degree. Time PRED+ is much smaller compared to time BF, see Fig.~\ref{Percentage_CPU_Saved} for the percentage of the CPU time saved by PRED+, which shows a saving of the CPU time basically more than 60\% and 40\% for the standard FEM and the mixed FEM, respectively. Last but not least, time PRED is negligible compared to time PRED+.

\begin{figure}[!ht]
\hspace{0.0cm}
\begin{subfigure}[b]{0.35\textwidth}
\scalebox{0.9}{
\begin{tikzpicture} 
\begin{axis}
[
    width=6cm,
    height=5cm,
    ymode=log,
    ymin=1e-3,
    ymax=1e7,    
    ylabel={CPU time in seconds},
    ytick={1e-3, 1e-1, 1e1, 1e3, 1e5, 1e7},
    yticklabels={1e-3, 1e-1, 1e1, 1e3, 1e5, 1e7},    
    xlabel={$p$},
    xtick={0,1,2,3,4},
    xticklabels={$1$, $2$, $3$, $4$, ${5}$},
    xlabel style={at={(0.5,-0.12)}},
    ylabel style={at={(-0.15,0.5)}},
    legend style={nodes={scale=0.7}},
    legend cell align={left} 
]
\addplot[black,mark=pentagon,mark options={color=black,fill=black}] coordinates {(0,2.1e-25)}; 
\addplot[black,mark=Mercedes star,mark options={color=black,fill=black}] coordinates {(0,2.1e-25)}; 

\addplot[blue,mark=pentagon,mark options={color=blue,fill=blue}] coordinates {(0,0.026) (1,0.017) (2,0.021) (3,0.013) (4,0.028)}; 
\addplot[blue,mark=Mercedes star,mark options={color=blue,fill=blue}] coordinates {(0,1.4) (1,0.24) (2,0.2) (3,0.22) (4,0.2)}; 

\addplot[red,mark=pentagon,mark options={color=red,fill=red}] coordinates {(0,0.546) (1,0.181) (2,0.298) (3,0.08) (4,0.39)}; 
\addplot[red,mark=Mercedes star,mark options={color=red,fill=red}] coordinates {(0,35000)};
\addplot[red,mark=Mercedes star,mark options={color=red,fill=red}] coordinates {(1,300) (2,35) (3,15) (4,12)};
\draw [red,dashed] (axis cs:0,35000) -- (axis cs:1,300);

\legend{PRED, BF};
\end{axis}
\end{tikzpicture}
}
\vspace{-0.2cm}
\caption{Solution}
\end{subfigure}
\hspace{-0.7cm}
\begin{subfigure}[b]{0.35\textwidth}
\scalebox{0.9}{
\begin{tikzpicture} 
\begin{axis}
[
    width=6cm,
    height=5cm,
    ymode=log,
    ymin=1e-3,
    ymax=1e7,    
    ylabel={CPU time in seconds},
    ytick={1e-3, 1e-1, 1e1, 1e3, 1e5, 1e7},
    yticklabels={1e-3, 1e-1, 1e1, 1e3, 1e5, 1e7},    
    xlabel={$p$},
    xtick={0,1,2,3,4},
    xticklabels={$1$, $2$, $3$, $4$, ${5}$},
    xlabel style={at={(0.5,-0.12)}},
    ylabel style={at={(-0.15,0.5)}},
    legend style={nodes={scale=0.7}},
    legend cell align={left}
]
\addplot[blue,mark=pentagon,mark options={color=blue,fill=blue}] coordinates {(0,0.026) (1,0.027) (2,0.050) (3,0.028) (4,0.028)}; 
\addplot[blue,mark=Mercedes star,mark options={color=blue,fill=blue}] coordinates {(0,46) (1,4) (2,1.4) (3,0.5) (4,0.64)}; 

\addplot[red,mark=pentagon,mark options={color=red,fill=red}] coordinates {(0,0.55) (1,0.33) (2,0.57) (3,0.27) (4,0.39)}; 
\addplot[red,mark=Mercedes star,mark options={color=red,fill=red}] coordinates {(0,2200) (1,75) (2,17) (3,16) (4,12)}; 
\end{axis}
\end{tikzpicture}
}
\vspace{-0.2cm}
\caption{First derivative}
\end{subfigure}
\hspace{-0.7cm}
\begin{subfigure}[b]{0.35\textwidth}
\scalebox{0.9}{
\begin{tikzpicture} 
\begin{axis}
[
    width=6cm,
    height=5cm,
    ymode=log,
    ymin=1e-3,
    ymax=1e7,    
    ylabel={CPU time in seconds},
    ytick={1e-3, 1e-1, 1e1, 1e3, 1e5, 1e7},
    yticklabels={1e-3, 1e-1, 1e1, 1e3, 1e5, 1e7},    
    xlabel={$p$},
    xtick={0,1,2,3,4},
    xticklabels={$1$, $2$, $3$, $4$, ${5}$},
    xlabel style={at={(0.5,-0.12)}},
    ylabel style={at={(-0.15,0.5)}},
    legend style={nodes={scale=0.7}},
    legend cell align={left}  
]
\addplot[blue,mark=pentagon,mark options={color=blue,fill=blue}] coordinates {(1,0.04) (2,0.05) (3,0.046) (4,0.047)}; 
\addplot[blue,mark=Mercedes star,mark options={color=blue,fill=blue}] coordinates {(1,64) (2,5.4) (3,1.8) (4,1.2)}; 

\addplot[red,mark=pentagon,mark options={color=red,fill=red}] coordinates {(0,0.55) (1,0.33) (2,0.57) (3,0.51) (4,0.75)}; 
\addplot[red,mark=Mercedes star,mark options={color=red,fill=red}] coordinates {(0,280000)};
\addplot[red,mark=Mercedes star,mark options={color=red,fill=red}] coordinates {(1,2500) (2,145) (3,62) (4,25)};
\draw [red,dashed] (axis cs:0,280000) -- (axis cs:1,2500);
\end{axis}
\end{tikzpicture}
}
\vspace{-0.2cm}
\caption{Second derivative}
\end{subfigure}
\caption{Comparison of the CPU time to obtain $E_{\rm min}$ for Eq. (\ref{1D_Helmholtz_equation_application}) using the algorithm and the brute-force refinement. The blue color denotes the standard FEM, and the red color denotes the mixed FEM.}
\label{CPU_algorithm_brute_force}
\end{figure}


\vspace{-0.5cm}
\begin{figure}[!ht]
\centering
\scalebox{0.9}{
\begin{tikzpicture}
\begin{axis}
[
    width=6cm,
    height=5cm,
    ymin=20,
    ymax=100,
    ylabel={CPU time saved},
    ylabel style={at={(-0.16,0.5)},font=\small},
    y tick label style={font=\footnotesize},
    yticklabel=\pgfmathprintnumber{\tick}\,$\%$,
    xtick={0,1,2,3,4},
    xticklabels={$1$, $2$, $3$, $4$, ${5}$},
    xlabel={$p$},
    xlabel style={at={(0.5,-0.12)}}, 
    legend style={nodes={scale=0.8},at={(0.65,0.2)},anchor=west},
    legend cell align={left}    
]
\addplot[black,mark=o,mark options={color=black,fill=black}] coordinates {(0,2.1e-25)};
\addplot[black,mark=diamond,mark options={color=black,fill=black}] coordinates {(0,2.1e-25)};
\addplot[black,mark=triangle,mark options={color=black,fill=black}] coordinates {(0,2.1e-25)};


\addplot[blue,mark=o,mark options={color=blue,fill=blue}] coordinates {(0,66.8) (1,55.8) (2,69.5) (3,82.0) (4,73.0)};
\addplot[blue,mark=diamond,mark options={color=blue,fill=blue}] coordinates {(0,80.6) (1,77.6) (2,81.1) (3,73.6) (4,85.6)};
\addplot[blue,mark=triangle,mark options={color=blue,fill=blue}] coordinates {(0) (1,71.2) (2,66.5) (3,69.7) (4,78)};

\addplot[red,mark=o,mark options={color=red,fill=red}] coordinates {(0,44) (1,60.3) (2,54) (3,72.3) (4,72.4)};
\addplot[red,mark=diamond,mark options={color=red,fill=red}] coordinates {(0,84.5) (1, 57.8) (2, 38.5) (3, 69.3) (4, 70.7)};
\addplot[red,mark=triangle,mark options={color=red,fill=red}] coordinates {(0,50) (1,69.8) (2,45.8) (3, 65.3) (4, 56.1)};
\legend{$u$,$u_x$,$u_{xx}$};
\end{axis}
\end{tikzpicture}
}
\caption{Percentage of CPU time saved using the algorithm. The blue color denotes the standard FEM, and the red color denotes the mixed FEM.}
\label{Percentage_CPU_Saved}
\end{figure}


\section{Conclusions}		\label{paragraph on conclusion}

A novel approach is presented to predict the highest attainable accuracy for second-order ordinary differential equations using the finite element methods.
In contrast to the brute-force approach, which uses successive $h$-refinements, this approach uses only a few coarse grid refinements. 
This approach is viable for the solution and its first and second derivative, for both the standard FEM and the mixed FEM, and different element degrees.
The algorithm for implementing the approach shows that the highest attainable accuracy can be accurately predicted and the CPU time is significantly reduced.
To compute the solution of the highest attainable accuracy using our approach, the CPU time can be saved more than 60\% for the standard FEM and 40\% for the mixed FEM.

Future research will focus on the validation of the approach for 2D second-order problems, where the influence of the linear system solver, local mesh refinement and boundary conditions might be significantly different from 1D problems. 

\appendix

\section{Derivation of the weak form}		\label{weak form appendix}

\subsection{The standard FEM}		\label{derivation_weak_form_SM}

Multiply Eq. (\ref{1D_general_Helmholtz_equation}) by a test function $\eta \in H ^1 (I)$, and integrate it over $I$ yields
\begin{equation}
(\eta, \, -\left(d u_x \right)_x + ru) = (\eta, \, f). \label{1D_general_inte}
\end{equation}

By applying Gauss's theorem for the first term of the left-hand side of Eq. (\ref{1D_general_inte}), we obtain
\begin{equation}
 ({\eta} _x, \, d u_x) + (\eta, \, ru) = (\eta, \, f) + \left( \eta, \, d u_x n \right)_{ {\Gamma_N}},		\label{1D_general_gauss}
\end{equation}
which gives that shown in Eq.~({\ref{1D_general_SM_weak_form_Diri_strong}}).

\subsection{The mixed FEM}		\label{derivation_weak_form_MM}
First, Eq. (\ref{Gene_MM_strong1}) is multiplied by a test function of $v$, i.e. $w \in H _{N0}^{1}(I)$, and integrated over $I$, which yields
\begin{subequations}
\begin{align}
  ( d^{-1}v + u _x, w) = 0,	\label{Gene_MM_weak1_a}
\end{align}
and then, it becomes
\begin{align}
 (w, \, d^{-1}v) - (w_x, \,  u ) = -(w, \, g n)_{\Gamma_D},		\label{Gene_MM_weak1_b}
\end{align}				\label{Gene_MM_weak1}%
by applying Gauss's theorem.
\end{subequations}

Next, Eq. (\ref{Gene_MM_strong2}) is multiplied by a test function of $u$, i.e. $q \in L^2 (I)$, and integrated over $I$, yielding 
\begin{align}
- ( q , \, v_x) + (q, \, ru) = (q, \, f ). \label{Gene_MM_weak2}
\end{align}

Eq.~(\ref{Gene_MM_weak1_b}) and Eq.~({\ref{Gene_MM_weak2}}) result in those shown in Eq. (\ref{1D_General_MM_weak_2in1}).

\newpage

\bibliographystyle{unsrt}  
\bibliography{mybibfile}  %%% Remove comment to use the external .bib file (using bibtex). 3_writing/1_1d/


\end{document}
